---
layout: post
title:  "Graphs"
date:   2025-01-13 14:56:36 -0300
categories:
---

I was assigned a college project on [graphs](https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)) and decided to share
my implementation with the world since these are very interesting and useful data structures, and, also, because I got an A at
it so I guess it should be good enough to go public.

This is the graph we will be discussing:
![Graph](../../../visual_assets/undirected_graph.png)

The image shows an undirected graph, and, as you can see, it is indeed undirected since edges (also known as links) such
as $$ 8 \to 7 $$ are equivalent to $$ 7 \to 8 $$. Furthermore, you may notice that the graph is **weighted** which will be important
in the future as we will be implementing breadth-first search and Kruskal's algorithm.

Still, before we delve into the realm of graph algorithms, we aim to visualize it first and foremost.
In order to achieve this, clever people came up (or discovered if you will) two main ways of *describing* graphs:

- [Adjacency list](https://en.wikipedia.org/wiki/Adjacency_list)
- [Adjacency matrix](https://en.wikipedia.org/wiki/Adjacency_matrix)

This is a very important point regarding this data structure: although graphs are usually pictured 
like the screenshot above i.e with cute, rounded vertices and clear weights in the edges, in 
real life, people work with *representations* of them. I do not know why's that but I am guessing
it's easier and, specially when implemented in a low level language, you get to confront
the **multidimensionality** of graphs.

### Project structure
I coded this in C, partly because it's mandatory as per course specification, although I should mention
that I enjoy coding in this language. The project's structure is available below and can be accessed
by appending `projects/graphs` to my blog's root URL so you can see it all.

I wholeheartedly receive critics, suggestions, and contributions, but since I have zero expectations
regarding people commiting to this project, it's not Git versioned (yet!).

- [graph.c](../../../projects/graphs/graph.c)
- [graph.h](../../../projects/graphs/graph.h)
- [main.c](../../../projects/graphs/main.c)
- [queue.c](../../../projects/graphs/queue.c)
- [queue.h](../../../projects/graphs/queue.h)

The first two `graph.h` and `graph.c` files correspond to definitions and implementations of the graph API which we will
be using in `main.c`, whereas `queue.h` and `queue.c` contain the definitions and implementations
of a simple FIFO [queue](https://en.wikipedia.org/wiki/Queue_(abstract_data_type)).

### Code description

Let us first understand the declared data types in `graph.h` used to represent the graph using a bottom-up approach: 
{% highlight c %}
{% include_absolute projects/graphs/graph.h, 4-17 %}
{% endhighlight %}


The `Neighbour` struct represents an adjacency list of an arbitrary vertex `i` -- showing
the `vertexValue` of the neighbouring node, the `weight` of its edge and a pointer to the `next` possible neighbouring
node of `i`. You can keep traversing this linked list until you hit the case in which `next` is `NULL`, indicating
that there are no more neighbours of `i` left.

The `Graph` type includes two simple integer counters that track the *maximum* number of vertices `nv` 
-- read-only, passed during initialization -- and the number of edges `ne` that grows as these are included in the DS.
The `Neighbour** nb` has the actual graph representation as a list of adjacency lists: you get the neighbours of
a given vertex `i` by reading `nb[i]` in linear time.

I should say, though, that the `graph.h` was supplied as part of the assignment and, thus, I couldn't really
think of new, more interesting ways of representing the graph, but I think that having $$ O(n) $$ time complexity
here shouldn't be much of an issue. Also, I do not know of further optimizations people do regarding this DS:
[it's a whole part of Computer Science](https://en.wikipedia.org/wiki/Graph_theory).

The last custom type is called `Edge` which I created for use in [Kruskal's algorithm](https://en.wikipedia.org/wiki/Kruskal%27s_algorithm):
{% highlight c %}
{% include_absolute projects/graphs/graph.h, 20-24 %}
{% endhighlight %}

The significant difference from this data type to `Neighbour` lies in the fact that `Edge`
encapsulates all the necessary information for describing an edge in a graph inside its memory
layout. The two vertices `u` and `v` along with the weight are all the information needed
to generate a [minimum spanning tree](https://en.wikipedia.org/wiki/Minimum_spanning_tree). More on that later.

Finally, the ~~public~~ exposed functions from the `graph.c` file are listed below:
{% highlight c %}
{% include_absolute projects/graphs/graph.h, 26-32 %}
{% endhighlight %}

I won't blab about all these functions since some are trivial to understand and quite standard from a C programming perspective.
The focus of this post lies on `bfs`, `kruskal`, and some `static` helper functions declared in the source file which are crucial
for the latter.

Still, before we dive deep into breadth-first search and Kruskal's, I'll unfurl the queue implementation for a matter
of completion. Feel free to skip it, if you fancy.

{% highlight c %}
{% include_absolute projects/graphs/queue.h, 4-17 %}
{% endhighlight %}

The queue will only really be used in BFS. As such, the first type `QueueNode` only needs a pointer
to the neighbouring vertex and another one for the next node in queue.
The `Queue` itself has members for the front and the back of the ADT, since 
we'll be needing constant time for both `front` read and `back` write -- afterall, this where this data
structure excels.

The exposed functions are:
{% highlight c %}
{% include_absolute projects/graphs/queue.h, 20-24 %}
{% endhighlight %}

Again, pretty usual stuff. Both `enqueue` and `dequeue` run in $$O(1)$$ time just like a standard queue.
`is_queue_empty` evaluates the `q->front` pointer giving us information on remaining vertices in queue.
Consequentially, we are able control the graph traversal using this auxiliary structure.

An interesting difference in my `dequeue` implementation is that it encompasses **peeking and popping**, i.e.
it returns the `QueueNode` in front of the queue and moves on with it. I found this approach
easier to implement in the BFS algorithm, even though you have to be extra careful regarding leaking
memory and losing information.

### Breadth-first search (BFS)

The BFS implementation starts with the creation of two auxiliary structures necessary for the graph traversal logic.
A `verticesToVisit` queue which holds enqueued vertices during the traversal for the later exploration
of their neighbours. 

{% highlight c %}
{% include_absolute projects/graphs/graph.c, 121-138 %}
{% endhighlight %}

Notice that the `visited` array is a pointer of `int` and is allocated using `calloc`. Unlike the college canon, `malloc`,
this API allocates a block of memory and [zero initializes all of its bytes to zero](https://en.cppreference.com/w/c/memory/calloc).
Due to this behavior, I could leverage the initial status of zero (false) in the `visited` array as a way of saying that all
vertices were initially unvisited, which makes sense.

At the end of the day, this array is just a pointer to boolean states, so you may query
`visited[i]` of a given vertex `i` and check its result: $$1$$ in case it has been visited, $$0$$ otherwise.
All in all, it behaves just like the `g->nb` list of adjacency lists of the graph.

The gist of the algorithm lies in a `do {...} while()` loop. The old implementation I made used a "usual" `while` loop, but it 
required an auxiliary, heap allocated `initialVertex` variable to be enqueued and, thus, allow the loop to start.
Once again, I do not know if I made the right decision -- if there's such thing --, but I refactored the algorithm to 
make use of the former C construct.

{% highlight c %}
{% include_absolute projects/graphs/graph.c, 140-146 %}
{% include_absolute projects/graphs/graph.c, 153-154 %}
{% include_absolute projects/graphs/graph.c, 162-162 %}
{% include_absolute projects/graphs/graph.c, 189-189 %}
{% endhighlight %}



I found this interesting because such construct immediately enters the loop's body and *later* evaluates the condition,
so it's like the semantics of it express that the **initial run will be different** (which it is). It also discarded
the use of the previously mentioned `initialVertex` heap variable and hacky first-time enqueuing.

The refactoring led to some branching in the loop's internal (to detect if it's a first run), but I don't think it negatively impacted
readability. I know `do {...} while()` loops aren't new in programming, but I rarely used them. Using them in this context
exposed me a to a **new way of thinking about and solving the problem**, which is one of the guiding principles of 
my [ethos](https://en.wikipedia.org/wiki/Ethos), so hooray I guess!
